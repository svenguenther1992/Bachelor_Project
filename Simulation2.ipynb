{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WFgIjRnJK_Eb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4VZ7IEA_LSQJ"
   },
   "outputs": [],
   "source": [
    "def simulate_repeated_anova(means, cov_matrix, repetition, repetition_cv,\n",
    "                            folds_cv, sample_size, seed, detailed = False):\n",
    "\n",
    "  #This initiates a dictionary that will be the result table in the end\n",
    "  result_dict = {\"Repetition\":[], \"RM-ANOVA\":[], \"Greenhouse-Geisser\":[],\n",
    "                 \"Huynh-Feldt\":[], \"Cross-Validation\":[]}\n",
    "\n",
    "  #To make the results replicable, a seed for the pseudorandomly\n",
    "  #generated data is set\n",
    "  rnd_seed = seed\n",
    "\n",
    "\n",
    "  #For every repetition, this loop over data generation & model computation\n",
    "  for n in range(repetition):\n",
    "\n",
    "    np.random.seed(rnd_seed)\n",
    "    result_dict[\"Repetition\"].append(n+1)\n",
    "\n",
    "    #(Pseudo-)Random data generation\n",
    "    #First, it is checked which type of distribution was specified\n",
    "    #then, the function will loop over the list of touples and create random\n",
    "    #data for each repeated measure, which is then stored in a dictionary called\n",
    "    #\"generate_dict\")\n",
    "\n",
    "    #Data generation from multivariate normal distribution\n",
    "    generate_dict = {}\n",
    "    generate = np.random.multivariate_normal(means, cov_matrix, sample_size)\n",
    "\n",
    "    #Store data for each measurement in a dictionary for RM ANOVA\n",
    "    count = 1\n",
    "    for measurement in generate.T:\n",
    "      generate_dict[f\"Measurement{count}\"] = measurement\n",
    "      count += 1\n",
    "\n",
    "\n",
    "    #Repeated Measures ANOVA (Standard Analysis)\n",
    "    #Number of repeated measures\n",
    "    n_measures = len(generate_dict.keys())\n",
    "\n",
    "    #Calculate grand mean\n",
    "    grand_mean = np.array([generate_dict[k] for k in generate_dict]).mean()\n",
    "\n",
    "    #Calculate sums of squares\n",
    "    #SS Total\n",
    "    ss_total = 0\n",
    "    for n in generate_dict.keys():\n",
    "      for m in generate_dict[n]:\n",
    "        ss_total += (m-grand_mean)**2\n",
    "\n",
    "    #SS Subject\n",
    "    sum_squared = 0\n",
    "    for n in range(sample_size):\n",
    "      subject_sum = 0\n",
    "      for key in generate_dict:\n",
    "        subject_sum += generate_dict[key][n]\n",
    "      sum_squared += ((subject_sum/n_measures)-grand_mean)**2\n",
    "    ss_subject = n_measures*sum_squared\n",
    "\n",
    "    #SS Measure\n",
    "    sum_measure = 0\n",
    "    for measure in generate_dict.keys():\n",
    "      sum_measure += (np.mean(generate_dict[measure])-grand_mean)**2\n",
    "    ss_measure = sum_measure*sample_size\n",
    "\n",
    "    #SS Error\n",
    "    ss_error = ss_total - ss_subject - ss_measure\n",
    "\n",
    "    #Degrees of Freedom\n",
    "    df_subject = sample_size-1\n",
    "    df_measure = n_measures-1\n",
    "    df_error = df_subject*df_measure\n",
    "    df_total = sample_size*n_measures - 1\n",
    "\n",
    "    #MS\n",
    "    ms_measure = ss_measure/df_measure\n",
    "    ms_error = ss_error/df_error\n",
    "\n",
    "    #F-test & p-value\n",
    "    F = ms_measure/ms_error\n",
    "    p_value = stats.f.sf(F,df_measure,df_error,loc=0,scale=1)\n",
    "\n",
    "    #append p-value to the result dictionary\n",
    "    result_dict[\"RM-ANOVA\"].append(p_value)\n",
    "\n",
    "\n",
    "    #Correction Methods\n",
    "\n",
    "    #Greenhouse-Geisser (GG) Correction\n",
    "    #Create Covariance Matrix\n",
    "    measures_list = [generate_dict[n] for n in generate_dict.keys()]\n",
    "    measures_array = np.array(measures_list)\n",
    "    m_cov = np.cov(measures_array)\n",
    "\n",
    "    #Total Mean for all measures\n",
    "    total_mean = sum([row.mean() for row in m_cov])/len(m_cov)\n",
    "\n",
    "    #Double Centering\n",
    "    t=0\n",
    "    for n in range(len(m_cov)):\n",
    "      for l in range(len(m_cov)):\n",
    "        t += ((m_cov[n][l]-total_mean)-(m_cov[n].mean()-total_mean)-(m_cov[l].mean()-total_mean))**2\n",
    "    s=0\n",
    "    for n in range(len(m_cov)):\n",
    "      s += m_cov[n][n]-total_mean-2*(m_cov[n].mean()-total_mean)\n",
    "      u = s**2\n",
    "\n",
    "    #Epsilon (degree of sphericity)\n",
    "    epsilon = u/((len(m_cov)-1)*t)\n",
    "\n",
    "    #Adjusted degrees of freedom\n",
    "    v1 = (len(m_cov)-1)*epsilon\n",
    "    v2 = v1*(sample_size-1)\n",
    "\n",
    "    #P-Value for GG\n",
    "    p_value_gg = stats.f.sf(F,v1, v2,loc=0,scale=1)\n",
    "\n",
    "    #append p_value_gg to result dictionary\n",
    "    result_dict[\"Greenhouse-Geisser\"].append(p_value_gg)\n",
    "\n",
    "\n",
    "    #Huynh-Feldt Correction\n",
    "    #Adjusted Epsilon and adjusted degrees of freedom\n",
    "    epsilon_hf = (sample_size*(len(m_cov)-1)*epsilon-2)/((len(m_cov)-1)*(sample_size-1-((len(m_cov)-1)*epsilon)))\n",
    "    v1_hf = (len(m_cov)-1)*epsilon_hf\n",
    "    v2_hf = v1_hf*(sample_size-1)\n",
    "\n",
    "    p_value_hf = stats.f.sf(F,v1_hf, v2_hf,loc=0,scale=1)\n",
    "\n",
    "    #Append p_value_hf to result dictionary\n",
    "    result_dict[\"Huynh-Feldt\"].append(p_value_hf)\n",
    "\n",
    "\n",
    "    #Cross-Validation approach\n",
    "    #Prediction by Mean (to pass to sklearn cross-validation function)\n",
    "    #Note: this is not necessary for regression as this model exists already\n",
    "    #in the Sklearn package\n",
    "    class MeanPredictor():\n",
    "\n",
    "      def __init__(self, mean = None):\n",
    "        if mean is not None:\n",
    "          self.mean = mean\n",
    "        else:\n",
    "          self.mean = None\n",
    "\n",
    "      def fit(self, X, Y):\n",
    "        self.mean = np.mean(Y)\n",
    "\n",
    "      def predict(self, X):\n",
    "        return np.full(X.shape[0], self.mean)\n",
    "\n",
    "      def get_params(self, deep = False):\n",
    "        return {\"mean\":self.mean}\n",
    "\n",
    "\n",
    "    #Models for comparison (LinearRegression is from Sklearn library)\n",
    "    models = [(\"Prediction by Mean\", MeanPredictor()),\n",
    "              (\"Linear Regression\", LinearRegression())]\n",
    "\n",
    "    #For cross-validation of the Sklearn library a dataframe is created\n",
    "    rm_dict = {}\n",
    "    rm_dict[\"Subject\"] = []\n",
    "    rm_dict[\"Measurement\"] = []\n",
    "    rm_dict[\"Score\"] = []\n",
    "\n",
    "    for n in range(len(generate)):\n",
    "      count = 1\n",
    "      for m in generate[n]:\n",
    "        rm_dict[\"Subject\"].append(n+1)\n",
    "        rm_dict[\"Measurement\"].append(count)\n",
    "        rm_dict[\"Score\"].append(m)\n",
    "        count += 1\n",
    "\n",
    "    rm_df = pd.DataFrame(rm_dict)\n",
    "\n",
    "    #X needs to be passed as a dummy variable to regression\n",
    "    X = pd.get_dummies(rm_df[\"Measurement\"])\n",
    "\n",
    "    #Initiate a win count (counts win for every cv-repetition)\n",
    "    wins = 0\n",
    "\n",
    "    #For every repetition run cross-validation with mean & factor model\n",
    "    #Note: GroupShuffleSplit is just a splitter. By setting the test_size equal\n",
    "    #to 0.1 for 10 folds, and 0.2 for 5 folds, we get a 10-fold and 5-fold cv,\n",
    "    #respectively.\n",
    "    if folds_cv == 10:\n",
    "      test_size = 0.1\n",
    "    else:\n",
    "      test_size = 0.2\n",
    "\n",
    "    #For every repetition run cross-validation with mean & factor model\n",
    "    for n in range(repetition_cv):\n",
    "\n",
    "      #We use grouped cross-validation --> GroupShuffleSplit\n",
    "      gss = GroupShuffleSplit(n_splits = folds_cv, test_size = test_size,\n",
    "                              random_state = n)\n",
    "\n",
    "      score1 = np.sqrt(cross_val_score(MeanPredictor(), X, rm_df[\"Score\"],\n",
    "                                       groups = rm_df[\"Subject\"],\n",
    "                                       scoring='neg_mean_squared_error',\n",
    "                                       cv=gss, n_jobs=-1).mean()*-1)\n",
    "\n",
    "      score2 = np.sqrt(cross_val_score(LinearRegression(), X, rm_df[\"Score\"],\n",
    "                                       groups = rm_df[\"Subject\"],\n",
    "                                       scoring='neg_mean_squared_error',\n",
    "                                       cv=gss, n_jobs=-1).mean()*-1)\n",
    "\n",
    "      #Compare scores\n",
    "      if score1 < score2:\n",
    "        wins += -1\n",
    "      elif score1 > score2:\n",
    "        wins += 1\n",
    "      else:\n",
    "        wins = wins\n",
    "\n",
    "    #Depending on which model wins, append the winner to the result table\n",
    "    if wins > 0:\n",
    "      result_dict[\"Cross-Validation\"].append(\"Factor\")\n",
    "    elif wins < 0:\n",
    "      result_dict[\"Cross-Validation\"].append(\"Mean\")\n",
    "    else:\n",
    "      result_dict[\"Cross-Validation\"].append(\"Even\")\n",
    "\n",
    "\n",
    "    #To not generate the same data twice, the seed is changed for the next rep.\n",
    "    rnd_seed += 1\n",
    "\n",
    "  #AFTER all repetitions are finished:\n",
    "  #If detailed = True, a table is constructed that displays the results for\n",
    "  #every repetition\n",
    "  if detailed == True:\n",
    "\n",
    "    #This puts the result table together that is displayed in the end\n",
    "    result_df = pd.DataFrame(result_dict,\n",
    "                            columns=[\"RM-ANOVA\", \"Greenhouse-Geisser\",\n",
    "                                     \"Huynh-Feldt\", \"Cross-Validation\"],\n",
    "                            index = result_dict[\"Repetition\"])\n",
    "\n",
    "    #Table formatting\n",
    "    #The following two functions color significant/factor model results\n",
    "    def color_significant(value):\n",
    "      if value > 0.05:\n",
    "        color = \"red\"\n",
    "      else:\n",
    "        color = \"green\"\n",
    "      return \"color: %s\" % color\n",
    "\n",
    "    def factor_color(model):\n",
    "      if model == \"Mean\":\n",
    "        color = \"red\"\n",
    "      else:\n",
    "        color = \"green\"\n",
    "      return \"color: %s\" % color\n",
    "\n",
    "    #Sort table by the p-values for RM ANOVA in descending order\n",
    "    result_df = result_df.sort_values(\"RM-ANOVA\", ascending=False)\n",
    "\n",
    "    #Apply all styles to the table\n",
    "    result_df = (result_df.style\n",
    "      .hide_index()\n",
    "      .applymap(color_significant, subset=[\"RM-ANOVA\", \"Greenhouse-Geisser\",\n",
    "                                           \"Huynh-Feldt\"])\n",
    "      .applymap(factor_color, subset=[\"Cross-Validation\"])\n",
    "      .format({\"RM-ANOVA\": \"{:.4f}\", \"Greenhouse-Geisser\": \"{:.4f}\",\n",
    "               \"Huynh-Feldt\": \"{:.4f}\"}))\n",
    "\n",
    "    return result_df\n",
    "\n",
    "  #If detailed = False, the relative frequencies of significant results (for\n",
    "  #ANOVA and Welch) and factor-model wins (CV) are returned\n",
    "  else:\n",
    "    ratio_dict = {}\n",
    "    ratio_dict[\"RM-ANOVA\"] = sum(i <= 0.05 for i in result_dict[\"RM-ANOVA\"])/repetition\n",
    "    ratio_dict[\"Greenhouse-Geisser\"] = sum(i <= 0.05 for i in result_dict[\"Greenhouse-Geisser\"])/repetition\n",
    "    ratio_dict[\"Huynh-Feldt\"] = sum(i <= 0.05 for i in result_dict[\"Huynh-Feldt\"])/repetition\n",
    "    ratio_dict[\"Cross-Validation\"] = sum(i == \"Factor\" for i in result_dict[\"Cross-Validation\"])/repetition\n",
    "\n",
    "    return ratio_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1BHO4OslLbwg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Means                                         Cov_Matrix  \\\n",
      "0       [1, 1, 1]  [[0.25, 0.1, 0.1], [0.1, 0.25, 0.1], [0.1, 0.1...   \n",
      "1       [1, 1, 1]  [[0.25, 0.1, 0.1], [0.1, 0.25, 0.1], [0.1, 0.1...   \n",
      "2       [1, 1, 1]  [[0.25, 0.1, 0.1], [0.1, 0.25, 0.1], [0.1, 0.1...   \n",
      "3       [1, 1, 1]  [[1.0, 0.4, 0.4], [0.4, 1.0, 0.4], [0.4, 0.4, ...   \n",
      "4       [1, 1, 1]  [[1.0, 0.4, 0.4], [0.4, 1.0, 0.4], [0.4, 0.4, ...   \n",
      "5       [1, 1, 1]  [[1.0, 0.4, 0.4], [0.4, 1.0, 0.4], [0.4, 0.4, ...   \n",
      "6       [1, 1, 1]  [[0.25, 0.1, 0.2], [0.1, 0.25, 0.2], [0.2, 0.2...   \n",
      "7       [1, 1, 1]  [[0.25, 0.1, 0.2], [0.1, 0.25, 0.2], [0.2, 0.2...   \n",
      "8       [1, 1, 1]  [[0.25, 0.1, 0.2], [0.1, 0.25, 0.2], [0.2, 0.2...   \n",
      "9       [1, 1, 1]  [[0.25, 0.1, 0.025], [0.1, 0.25, 0.1], [0.025,...   \n",
      "10      [1, 1, 1]  [[0.25, 0.1, 0.025], [0.1, 0.25, 0.1], [0.025,...   \n",
      "11      [1, 1, 1]  [[0.25, 0.1, 0.025], [0.1, 0.25, 0.1], [0.025,...   \n",
      "12      [1, 1, 1]  [[1.0, 0.4, 0.1], [0.4, 1.0, 0.4], [0.1, 0.4, ...   \n",
      "13      [1, 1, 1]  [[1.0, 0.4, 0.1], [0.4, 1.0, 0.4], [0.1, 0.4, ...   \n",
      "14      [1, 1, 1]  [[1.0, 0.4, 0.1], [0.4, 1.0, 0.4], [0.1, 0.4, ...   \n",
      "15      [1, 1, 1]  [[0.25, 0.1, 0.05], [0.1, 0.25, 0.2], [0.05, 0...   \n",
      "16      [1, 1, 1]  [[0.25, 0.1, 0.05], [0.1, 0.25, 0.2], [0.05, 0...   \n",
      "17      [1, 1, 1]  [[0.25, 0.1, 0.05], [0.1, 0.25, 0.2], [0.05, 0...   \n",
      "18  [1, 1.1, 1.2]  [[0.25, 0.1, 0.1], [0.1, 0.25, 0.1], [0.1, 0.1...   \n",
      "19  [1, 1.1, 1.2]  [[0.25, 0.1, 0.1], [0.1, 0.25, 0.1], [0.1, 0.1...   \n",
      "20  [1, 1.1, 1.2]  [[0.25, 0.1, 0.1], [0.1, 0.25, 0.1], [0.1, 0.1...   \n",
      "21  [1, 1.1, 1.2]  [[1.0, 0.4, 0.4], [0.4, 1.0, 0.4], [0.4, 0.4, ...   \n",
      "22  [1, 1.1, 1.2]  [[1.0, 0.4, 0.4], [0.4, 1.0, 0.4], [0.4, 0.4, ...   \n",
      "23  [1, 1.1, 1.2]  [[1.0, 0.4, 0.4], [0.4, 1.0, 0.4], [0.4, 0.4, ...   \n",
      "24  [1, 1.1, 1.2]  [[0.25, 0.1, 0.2], [0.1, 0.25, 0.2], [0.2, 0.2...   \n",
      "25  [1, 1.1, 1.2]  [[0.25, 0.1, 0.2], [0.1, 0.25, 0.2], [0.2, 0.2...   \n",
      "26  [1, 1.1, 1.2]  [[0.25, 0.1, 0.2], [0.1, 0.25, 0.2], [0.2, 0.2...   \n",
      "27  [1, 1.1, 1.2]  [[0.25, 0.1, 0.025], [0.1, 0.25, 0.1], [0.025,...   \n",
      "28  [1, 1.1, 1.2]  [[0.25, 0.1, 0.025], [0.1, 0.25, 0.1], [0.025,...   \n",
      "29  [1, 1.1, 1.2]  [[0.25, 0.1, 0.025], [0.1, 0.25, 0.1], [0.025,...   \n",
      "30  [1, 1.1, 1.2]  [[1.0, 0.4, 0.1], [0.4, 1.0, 0.4], [0.1, 0.4, ...   \n",
      "31  [1, 1.1, 1.2]  [[1.0, 0.4, 0.1], [0.4, 1.0, 0.4], [0.1, 0.4, ...   \n",
      "32  [1, 1.1, 1.2]  [[1.0, 0.4, 0.1], [0.4, 1.0, 0.4], [0.1, 0.4, ...   \n",
      "33  [1, 1.1, 1.2]  [[0.25, 0.1, 0.05], [0.1, 0.25, 0.2], [0.05, 0...   \n",
      "34  [1, 1.1, 1.2]  [[0.25, 0.1, 0.05], [0.1, 0.25, 0.2], [0.05, 0...   \n",
      "35  [1, 1.1, 1.2]  [[0.25, 0.1, 0.05], [0.1, 0.25, 0.2], [0.05, 0...   \n",
      "\n",
      "    Sample Size  RM ANOVA   GG   HF  Cross-Validation  \n",
      "0            20      0.04 0.04 0.04              0.12  \n",
      "1            50      0.08 0.08 0.08              0.08  \n",
      "2           100      0.04 0.04 0.04              0.12  \n",
      "3            20      0.04 0.04 0.04              0.12  \n",
      "4            50      0.08 0.08 0.08              0.08  \n",
      "5           100      0.04 0.04 0.04              0.12  \n",
      "6            20      0.03 0.03 0.03              0.15  \n",
      "7            50      0.05 0.04 0.04              0.06  \n",
      "8           100      0.04 0.01 0.02              0.11  \n",
      "9            20      0.07 0.06 0.06              0.10  \n",
      "10           50      0.06 0.06 0.06              0.07  \n",
      "11          100      0.05 0.05 0.05              0.14  \n",
      "12           20      0.07 0.06 0.06              0.10  \n",
      "13           50      0.06 0.06 0.06              0.07  \n",
      "14          100      0.05 0.05 0.05              0.14  \n",
      "15           20      0.04 0.03 0.03              0.20  \n",
      "16           50      0.05 0.04 0.04              0.08  \n",
      "17          100      0.04 0.02 0.02              0.10  \n",
      "18           20      0.25 0.23 0.25              0.49  \n",
      "19           50      0.66 0.65 0.65              0.62  \n",
      "20          100      0.90 0.90 0.90              0.93  \n",
      "21           20      0.10 0.08 0.09              0.16  \n",
      "22           50      0.17 0.16 0.16              0.19  \n",
      "23          100      0.29 0.29 0.29              0.49  \n",
      "24           20      0.21 0.14 0.16              0.35  \n",
      "25           50      0.33 0.28 0.29              0.40  \n",
      "26          100      0.58 0.54 0.54              0.68  \n",
      "27           20      0.23 0.19 0.22              0.34  \n",
      "28           50      0.52 0.51 0.52              0.54  \n",
      "29          100      0.87 0.86 0.86              0.92  \n",
      "30           20      0.08 0.08 0.08              0.16  \n",
      "31           50      0.22 0.21 0.21              0.23  \n",
      "32          100      0.27 0.27 0.27              0.42  \n",
      "33           20      0.20 0.14 0.14              0.35  \n",
      "34           50      0.29 0.21 0.22              0.41  \n",
      "35          100      0.53 0.50 0.51              0.65  \n"
     ]
    }
   ],
   "source": [
    "#Define parameters\n",
    "means = [[1, 1, 1], [1, 1.1, 1.2]]\n",
    "\n",
    "cov1 = np.array([[0.25, 0.1, 0.1],\n",
    "                [0.1, 0.25, 0.1],\n",
    "                [0.1, 0.1, 0.25]])\n",
    "\n",
    "cov2 = np.array([[1, 0.4, 0.4],\n",
    "                [0.4, 1, 0.4],\n",
    "                [0.4, 0.4, 1]])\n",
    "\n",
    "cov3 = np.array([[0.25, 0.1, 0.2],\n",
    "                [0.1, 0.25, 0.2],\n",
    "                [0.2, 0.2, 1]])\n",
    "\n",
    "cov4 = np.array([[0.25, 0.1, 0.025],\n",
    "                [0.1, 0.25, 0.1],\n",
    "                [0.025, 0.1, 0.25]])\n",
    "\n",
    "cov5 = np.array([[1, 0.4, 0.1],\n",
    "                [0.4, 1, 0.4],\n",
    "                [0.1, 0.4, 1]])\n",
    "\n",
    "cov6 = np.array([[0.25, 0.1, 0.05],\n",
    "                [0.1, 0.25, 0.2],\n",
    "                [0.05, 0.2, 1]])\n",
    "\n",
    "cov_list = [cov1, cov2, cov3, cov4, cov5, cov6]\n",
    "\n",
    "sample_sizes = [20, 50, 100]\n",
    "\n",
    "#Initiate dictionary for the results\n",
    "simulation_dict = {}\n",
    "simulation_dict[\"Means\"] = []\n",
    "simulation_dict[\"Sample Size\"] = []\n",
    "simulation_dict[\"Cov_Matrix\"] = []\n",
    "simulation_dict[\"RM ANOVA\"] = []\n",
    "simulation_dict[\"GG\"] = []\n",
    "simulation_dict[\"HF\"] = []\n",
    "simulation_dict[\"Cross-Validation\"] = []\n",
    "\n",
    "#Run simulations by looping over parameters\n",
    "for mean in means:\n",
    "  for cov in cov_list:\n",
    "    for size in sample_sizes:\n",
    "\n",
    "      if size == 100:\n",
    "        #This runs the simulation and stores it in a variable\n",
    "        simulation = simulate_repeated_anova(means=mean, cov_matrix=cov, folds_cv=10,\n",
    "                                repetition=100, repetition_cv=200,\n",
    "                                sample_size=size, seed=1, detailed = False)\n",
    "\n",
    "        #Pass results to simulation dictionary\n",
    "        simulation_dict[\"Means\"].append(mean)\n",
    "        simulation_dict[\"Cov_Matrix\"].append(cov)\n",
    "        simulation_dict[\"Sample Size\"].append(size)\n",
    "        simulation_dict[\"RM ANOVA\"].append(simulation[\"RM-ANOVA\"])\n",
    "        simulation_dict[\"GG\"].append(simulation[\"Greenhouse-Geisser\"])\n",
    "        simulation_dict[\"HF\"].append(simulation[\"Huynh-Feldt\"])\n",
    "        simulation_dict[\"Cross-Validation\"].append(simulation[\"Cross-Validation\"])\n",
    "\n",
    "      else:\n",
    "        #This runs the simulation and stores it in a variable\n",
    "        simulation = simulate_repeated_anova(means=mean, cov_matrix=cov, folds_cv=5,\n",
    "                                repetition=100, repetition_cv=200,\n",
    "                                sample_size=size, seed=1, detailed = False)\n",
    "\n",
    "        #Pass results to simulation dictionary\n",
    "        simulation_dict[\"Means\"].append(mean)\n",
    "        simulation_dict[\"Cov_Matrix\"].append(cov)\n",
    "        simulation_dict[\"Sample Size\"].append(size)\n",
    "        simulation_dict[\"RM ANOVA\"].append(simulation[\"RM-ANOVA\"])\n",
    "        simulation_dict[\"GG\"].append(simulation[\"Greenhouse-Geisser\"])\n",
    "        simulation_dict[\"HF\"].append(simulation[\"Huynh-Feldt\"])\n",
    "        simulation_dict[\"Cross-Validation\"].append(simulation[\"Cross-Validation\"])\n",
    "\n",
    "#Create dataframe to display as final table\n",
    "simulation_df = pd.DataFrame(\n",
    "    data = simulation_dict,\n",
    "    columns = [\"Means\", \"Cov_Matrix\", \"Sample Size\", \"RM ANOVA\", \"GG\", \"HF\",\n",
    "               \"Cross-Validation\"])\n",
    "\n",
    "#To have the full table printed (and results with 2 decimals)\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "print(simulation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9afF7MLLco-"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SImulation2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
